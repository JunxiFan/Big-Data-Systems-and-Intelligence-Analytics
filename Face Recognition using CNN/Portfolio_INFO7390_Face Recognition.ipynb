{"cells":[{"cell_type":"markdown","source":["# Face Recognition Using Convolutional Neural Network"],"metadata":{}},{"cell_type":"markdown","source":["This portfolio is about building an CNN model for face recognition using Keras."],"metadata":{}},{"cell_type":"markdown","source":["##I. Import Libiaries \nYou can run this notebook on databricks, after create libraries: *keras*, *opencv-python*, *tensorflow*.\nOr, you can run this notebook locally. Anaconda is a good choice."],"metadata":{}},{"cell_type":"code","source":["import os\nimport sys\nimport numpy as np\nimport cv2\nimport random\nimport numpy as np\nimport keras\nfrom sklearn.cross_validation import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras.models import load_model\nfrom keras import optimizers\nfrom keras import backend as K\nimport h5py \nfrom keras.models import model_from_json \nimport matplotlib.pyplot as plt\nimport pandas as pd"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["##II. Image Processing\nThe input shape of a CNN has rule, so before build our model, we need to process image dataset. We want to read graphs one by one, normalization, and add different labels to each of them according to the person shows on it, like ‘0’ for Bill and ‘1’ for Tom. \n\nWe use OpenCV, which has an image processing module that includes linear and non-linear image filtering, geometrical image transformations (resize, affine and perspective warping, generic table-based remapping), color space conversion, histograms, and so on. to adjust our images."],"metadata":{}},{"cell_type":"markdown","source":["When we read an image, suppose we have x pixel wide and y height image. OpenCV can read an image file and coverts it to a list (width × height × 3, 3 means three channels of colors as red, green, blue). To normalize the input data shape of our neural network model, for one images, we compare the width and height, and add borders to the shorter sides. At last, we resized the picture to 32 × 32 pixels format."],"metadata":{}},{"cell_type":"code","source":["IMAGE_SIZE = 64\n\ndef resize_image(image, height_output = IMAGE_SIZE, width_output = IMAGE_SIZE):\n     # initialize border's value. default value of four borders is 0\n    top, bottom, left, right = (0, 0, 0, 0)\n    \n    #get image's size\n    width, height, _ = image.shape\n    \n    #find the longer side of the image\n    longer_side = max(width, height)    \n    \n    #calculate how many we should add to the shorter side\n    if width < longer_side:\n        dh = longer_side - width\n        top = dh // 2\n        bottom = dh - top\n    elif height < longer_side:\n        dw = longer_side - height\n        left = dw // 2\n        right = dw - left\n    else:\n        pass \n    \n    #RGB\n    BLACK = [0, 0, 0]\n\n    # add border to make two sides the same. \"cv2.BORDER_CONSTANT \" is the color of border, configured by \"value\"\n    constant = cv2.copyMakeBorder(image, top , bottom, left, right, cv2.BORDER_CONSTANT, value = BLACK)\n    \n    return cv2.resize(constant, (height_output, width_output))"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["How to read hundreds of images with labels into our project is the next problem. Now we have many graphs of two people, for example, Bill Gates and Tom Cruise, separated in two folders.  After doing this classification, we can get a list of images and a list of related labels."],"metadata":{}},{"cell_type":"code","source":["#read data into ram\nimages = []\nlabels = []\ndef read_path(path_url):    \n    for dir_item in os.listdir(path_url):\n        full_path = os.path.abspath(os.path.join(path_url, dir_item))\n        \n        if os.path.isdir(full_path):    #if it is a folder, continue. (here a recursion is used)\n            read_path(full_path)\n        else: \n            if dir_item.endswith('.jpg'):\n                image = cv2.imread(full_path)                \n                image = resize_image(image, IMAGE_SIZE, IMAGE_SIZE)\n                images.append(image)                \n                labels.append(path_url)                                \n                    \n    return images,labels\n    \n#main function, read data\ndef load_dataset(path_url):\n    images,labels = read_path(path_url)\n  \n    #change images to 4-dimensions array\n    images = np.array(images)\n#     print(images.shape,\"total \")\n    \n    labels = np.array([0 if label.endswith('johnny_depp') else 1 for label in labels])    \n    return images, labels"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["We will do cross validation after training, so we split our dataset into three parts: Training, validation, and test sets. \n\nAlso, as it is a project about recognition, it’s necessary to do one-hot encoding to the labels. Label sets' shape will be a 2 dimention list, depends on the value of *nb_classes*. \n\nNext, change data type to float32 and normalize the value of RGB between 0-1, to improve network convergence speed, reduce training time, and reduce the value of training error.\n\nFor now, the preparation function before building CNN is complete."],"metadata":{}},{"cell_type":"code","source":["class Dataset:\n    def __init__(self, path_url):\n        #train data\n        self.train_images = None\n        self.train_labels = None\n        \n        #validate data\n        self.valid_images = None\n        self.valid_labels = None\n        \n        #test data\n        self.test_images  = None            \n        self.test_labels  = None\n        \n        #path of dataset\n        self.path_url = path_url\n        \n        #tensorflow (channels,rows,cols) or theano (rows,cols,channels)\n        self.input_shape = None\n        \n    # load dataset, then seperate dataset according to cross-validation\n    def load(self, nb_classes = 2):\n        #load dataset to ram\n        images, labels = load_dataset(self.path_url)        \n        \n        # split into three sets randomly\n        train_images, valid_images, train_labels, valid_labels = train_test_split(images, labels, test_size = 0.3, random_state = random.randint(0, 100))\n\n        _, test_images, _, test_labels = train_test_split(images, labels, test_size = 0.5, random_state = random.randint(0, 100))\n\n        self.input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)            \n            \n        #the amount of three data parts\n        print(train_images.shape[0], 'train samples')\n        print(valid_images.shape[0], 'valid samples')\n        print(test_images.shape[0], 'test samples')\n        \n        # label ===(one-hot encoding)===> 2 dimensions data\n        train_labels = np_utils.to_categorical(train_labels, nb_classes)                        \n        valid_labels = np_utils.to_categorical(valid_labels, nb_classes)            \n        test_labels = np_utils.to_categorical(test_labels, nb_classes)\n        \n        #image to float\n        train_images = train_images.astype('float32')            \n        valid_images = valid_images.astype('float32')\n        test_images = test_images.astype('float32')\n            \n        # normalize the value of RGB between 0-1\n        train_images /= 255\n        valid_images /= 255\n        test_images /= 255            \n        \n        self.train_images = train_images\n        self.valid_images = valid_images\n        self.test_images  = test_images\n        self.train_labels = train_labels\n        self.valid_labels = valid_labels\n        self.test_labels  = test_labels"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Next is load data from storage system. We have uploaded data source on DBFS (1062 jpg of Johnny Depp, 840 jpg of natalie portman), and read them here.\n\nAfter creating a new dataset object, including train_images, valid_images, test_images, train_labels, valid_labels, test_labels."],"metadata":{}},{"cell_type":"code","source":["dataset = Dataset('/dbfs/FileStore/tables/data/')    \ndataset.load()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["##III. Build CNN model\nKeras provides plenty of API for building neural network model. We can build a sequential convolutional neural network easily. For more details you can read [Keras official document layers part](https://keras.io/layers/about-keras-layers/)."],"metadata":{}},{"cell_type":"code","source":["def build_model(dataset, nb_classes = 2):\n    model = Sequential() \n\n    model.add(Conv2D(32, (3, 3), border_mode='same', \n                                 input_shape = dataset.input_shape))\n\n    model.add(Activation('relu'))\n    model.add(Conv2D(32, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))        \n    # droupout: present from Overfitting\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(nb_classes))\n    model.add(Activation('softmax'))\n    model.summary()\n    \n    return model"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["Our structure of CNN model:"],"metadata":{}},{"cell_type":"code","source":["MODEL = build_model(dataset)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["##IV.\tTrainning\nNext is let the dataset we have prepared to train this model and do cross validations. We set the cost function as ‘categorical_crossentropy’, a typical function dealing with categorical project. The optimizer is SGD (Stochastic gradient descent optimizer), at the same time, Keras includes support for momentum, learning rate decay, and Nesterov momentum, which means we can take multiple advantages from them. Using SGD only, the decent direction depends on batch data completely, so add a momentum can keep original decent direction in some degree, make the optimizer works faster, but more stable. We set the epoch as 100, and at last we get a graph using spark DataFrame."],"metadata":{}},{"cell_type":"code","source":["def train(dataset, model, batch_size = 40, nb_epoch = 100):\n    # SGD: a  compiler; lr: learning rate\n    sgd = SGD(lr = 0.001, decay = 1e-6, momentum = 0.9, nesterov = True) \n    \n    model.compile(loss='categorical_crossentropy',\n                  optimizer=sgd,\n                  metrics=['accuracy'])   \n\n    history = model.fit(dataset.train_images, dataset.train_labels,\n                   batch_size = batch_size,\n                   nb_epoch = nb_epoch,\n                   validation_data = (dataset.valid_images, dataset.valid_labels),\n                   shuffle = True)\n\n    res = history.history\n    return res"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["res = train(dataset, MODEL)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["i=1\ntemp_epoch = []\n\nfor each in range(len(res['acc'])):\n#   print(i)\n  temp_epoch.append(i)\n  i+=1\nres['epoch'] = temp_epoch\n\ndf = pd.DataFrame(res)\nspark_df = spark.createDataFrame(df)\ndisplay(spark_df)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["display(spark_df)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["##V.\tTest\nUsing test dataset we generate before to evaluate our training result. This test set was generated from the same source as train set and validation set, but we capture jpg randomly, so the test result is largely persuasive."],"metadata":{}},{"cell_type":"code","source":["def evaluate(model, dataset):\n    score = MODEL.evaluate(dataset.test_images, dataset.test_labels, verbose = 1)\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n#         print(type(score))\n    return score\n"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["evaluate(MODEL,dataset)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["class Model:\n    def __init__(self):\n        self.model = None \n        \n    def build_model(self, dataset, nb_classes = 2):\n        self.model = Sequential() \n        \n        self.model.add(Convolution2D(32, 3, 3, border_mode='same', \n                                     input_shape = dataset.input_shape))\n\n        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n        self.model.add(Convolution2D(32, 3, 3))\n        self.model.add(MaxPooling2D(pool_size=(2, 2)))        \n        # droupout: present from Overfitting\n        self.model.add(Dropout(0.25))\n        self.model.add(Flatten())\n        self.model.add(Dense(512, activation='relu')) \n        self.model.add(Dense(nb_classes, activation='softmax'))\n        self.model.summary()\n#train model\n    def train(self, dataset, loss, batch_size = 40, nb_epoch = 10):\n        # SGD  lr: learning rate\n        sgd = SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True) \n        \n        self.model.compile(loss=loss,\n                           optimizer=sgd,\n                           metrics=['accuracy'])   \n        \n        # nb_epoch： how many times should train the model.\n        # batch_size: how many data should be trained at one time\n        history = self.model.fit(dataset.train_images, dataset.train_labels,\n                       batch_size = batch_size,\n                       nb_epoch = nb_epoch,\n                       validation_data = (dataset.valid_images, dataset.valid_labels),\n                       shuffle = True)\n#         print('keys: ',history.history.keys())\n#         print(type(history.history))\n        res = history.history\n        return res\n        \n        \n    def evaluate(self, dataset):\n        score = self.model.evaluate(dataset.test_images, dataset.test_labels, verbose = 1)\n        print('Test loss:', score[0])\n        print('Test accuracy:', score[1])\n#         print(type(score))\n        return score"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":27}],"metadata":{"name":"Portfolio_INFO7390_Face Recognition","notebookId":1344617025196396},"nbformat":4,"nbformat_minor":0}
